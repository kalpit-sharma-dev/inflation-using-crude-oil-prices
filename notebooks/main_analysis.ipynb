{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecasting India's Inflation Using Crude Oil Prices\n",
        "## A Comparative Study of ARIMA and LSTM Models\n",
        "\n",
        "**Course:** Time Series Analysis (MAL7430)  \n",
        "**Institution:** Centre for Mathematical and Computational Economics, School of AI and Data Science, IIT Jodhpur\n",
        "\n",
        "---\n",
        "\n",
        "### Project Overview\n",
        "\n",
        "This notebook implements a comprehensive time series analysis comparing ARIMA and LSTM models for forecasting India's inflation based on global crude oil prices.\n",
        "\n",
        "**Main Objectives:**\n",
        "1. Examine the relationship between crude oil prices and inflation in India\n",
        "2. Build and train ARIMA and LSTM forecasting models\n",
        "3. Evaluate model performance using statistical metrics (RMSE, MAE, MAPE)\n",
        "4. Identify which model provides better forecasting accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import project modules\n",
        "from src.data_collection import collect_all_data\n",
        "from src.data_preprocessing import preprocess_data, test_stationarity\n",
        "from src.arima_model import build_arima_model, evaluate_arima_model, plot_acf_pacf\n",
        "from src.lstm_model import prepare_lstm_data, train_lstm_model, evaluate_lstm_model\n",
        "from src.model_evaluation import calculate_metrics, compare_models, plot_predictions, plot_residuals\n",
        "from src.visualization import plot_time_series, plot_correlation, plot_oil_inflation_relationship, plot_forecast_comparison\n",
        "import config\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect all data (Brent Crude Oil and India CPI)\n",
        "raw_data = collect_all_data()\n",
        "\n",
        "print(f\"\\nData shape: {raw_data.shape}\")\n",
        "print(f\"\\nData columns: {raw_data.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(raw_data.head())\n",
        "print(f\"\\nData summary:\")\n",
        "print(raw_data.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize raw data\n",
        "fig = plot_time_series(\n",
        "    raw_data, \n",
        "    columns=['Brent_Price', 'CPI'],\n",
        "    title='Raw Data: Brent Crude Oil Prices and India CPI'\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "processed_data, stationarity_results = preprocess_data()\n",
        "\n",
        "print(f\"\\nProcessed data shape: {processed_data.shape}\")\n",
        "print(f\"\\nProcessed data columns: {processed_data.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(processed_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize processed data with inflation rate\n",
        "fig = plot_time_series(\n",
        "    processed_data, \n",
        "    columns=['Brent_Price', 'Inflation_Rate'],\n",
        "    title='Processed Data: Brent Crude Oil Prices and Inflation Rate'\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot relationship between oil prices and inflation\n",
        "fig = plot_oil_inflation_relationship(\n",
        "    processed_data['Brent_Price'],\n",
        "    processed_data['Inflation_Rate'],\n",
        "    save_path=os.path.join(config.PATHS['figures'], 'oil_inflation_relationship.png')\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation analysis\n",
        "fig = plot_correlation(\n",
        "    processed_data,\n",
        "    columns=['Brent_Price', 'CPI', 'Inflation_Rate'],\n",
        "    title='Correlation Matrix: Oil Prices, CPI, and Inflation Rate',\n",
        "    save_path=os.path.join(config.PATHS['figures'], 'correlation_matrix.png')\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Print correlation values\n",
        "corr_matrix = processed_data[['Brent_Price', 'CPI', 'Inflation_Rate']].corr()\n",
        "print(\"\\nCorrelation Matrix:\")\n",
        "print(corr_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "target_variable = 'Inflation_Rate'\n",
        "target_data = processed_data[target_variable].dropna()\n",
        "\n",
        "train_size = int(len(target_data) * config.DATA_CONFIG['train_split'])\n",
        "train_data = target_data[:train_size]\n",
        "test_data = target_data[train_size:]\n",
        "\n",
        "print(f\"Total data points: {len(target_data)}\")\n",
        "print(f\"Training data: {len(train_data)} ({len(train_data)/len(target_data)*100:.1f}%)\")\n",
        "print(f\"Test data: {len(test_data)} ({len(test_data)/len(target_data)*100:.1f}%)\")\n",
        "print(f\"\\nTraining period: {train_data.index.min()} to {train_data.index.max()}\")\n",
        "print(f\"Test period: {test_data.index.min()} to {test_data.index.max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize train-test split\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "ax.plot(train_data.index, train_data.values, label='Training Data', linewidth=2, color='blue')\n",
        "ax.plot(test_data.index, test_data.values, label='Test Data', linewidth=2, color='red')\n",
        "ax.axvline(x=train_data.index[-1], color='black', linestyle='--', linewidth=2, label='Train/Test Split')\n",
        "ax.set_title('Train-Test Split', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel('Inflation Rate (%)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.PATHS['figures'], 'train_test_split.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ARIMA Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ACF and PACF for ARIMA parameter selection\n",
        "fig = plot_acf_pacf(train_data, lags=40)\n",
        "plt.savefig(os.path.join(config.PATHS['figures'], 'acf_pacf.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build and train ARIMA model\n",
        "arima_model, arima_order = build_arima_model(train_data, auto_select=True)\n",
        "\n",
        "print(f\"\\nSelected ARIMA order: {arima_order}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate ARIMA model\n",
        "arima_results = evaluate_arima_model(arima_model, test_data, train_data)\n",
        "\n",
        "print(\"\\nARIMA Model Metrics:\")\n",
        "for metric, value in arima_results['metrics'].items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LSTM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for LSTM\n",
        "scaled_train, scaler, X_train, y_train = prepare_lstm_data(\n",
        "    train_data,\n",
        "    sequence_length=config.LSTM_CONFIG['sequence_length'],\n",
        "    fit_scaler=True\n",
        ")\n",
        "\n",
        "print(f\"Training sequences shape: {X_train.shape}\")\n",
        "print(f\"Training targets shape: {y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare test data for LSTM\n",
        "_, _, X_test, y_test = prepare_lstm_data(\n",
        "    test_data,\n",
        "    sequence_length=config.LSTM_CONFIG['sequence_length'],\n",
        "    scaler=scaler,\n",
        "    fit_scaler=False\n",
        ")\n",
        "\n",
        "print(f\"Test sequences shape: {X_test.shape}\")\n",
        "print(f\"Test targets shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build and train LSTM model\n",
        "lstm_model, lstm_history = train_lstm_model(\n",
        "    X_train, y_train,\n",
        "    X_val=X_test,\n",
        "    y_val=y_test,\n",
        "    epochs=config.LSTM_CONFIG['epochs'],\n",
        "    batch_size=config.LSTM_CONFIG['batch_size']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate LSTM model\n",
        "lstm_results = evaluate_lstm_model(\n",
        "    lstm_model, X_test, y_test, scaler,\n",
        "    test_data_index=test_data.index\n",
        ")\n",
        "\n",
        "print(\"\\nLSTM Model Metrics:\")\n",
        "for metric, value in lstm_results['metrics'].items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models\n",
        "comparison_table = compare_models(arima_results, lstm_results, save_results=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(comparison_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot predictions comparison\n",
        "fig = plot_predictions(\n",
        "    test_data,\n",
        "    arima_results['forecasts'],\n",
        "    lstm_results['forecasts'],\n",
        "    title='Model Predictions Comparison'\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot forecast comparison with confidence intervals\n",
        "fig = plot_forecast_comparison(\n",
        "    test_data,\n",
        "    arima_results['forecasts'],\n",
        "    lstm_results['forecasts'],\n",
        "    arima_conf_int=arima_results.get('conf_int', None),\n",
        "    title='Forecast Comparison: ARIMA vs LSTM',\n",
        "    save_path=os.path.join(config.PATHS['figures'], 'forecast_comparison.png')\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"PROJECT SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n1. Data Overview:\")\n",
        "print(f\"   - Total data points: {len(processed_data)}\")\n",
        "print(f\"   - Date range: {processed_data.index.min()} to {processed_data.index.max()}\")\n",
        "print(f\"   - Training size: {len(train_data)} ({len(train_data)/len(target_data)*100:.1f}%)\")\n",
        "print(f\"   - Test size: {len(test_data)} ({len(test_data)/len(target_data)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n2. Model Performance:\")\n",
        "print(\"\\n   ARIMA Model:\")\n",
        "print(f\"   - Order: {arima_order}\")\n",
        "for metric, value in arima_results['metrics'].items():\n",
        "    print(f\"   - {metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n   LSTM Model:\")\n",
        "print(f\"   - Sequence length: {config.LSTM_CONFIG['sequence_length']}\")\n",
        "print(f\"   - Architecture: {config.LSTM_CONFIG['units']}\")\n",
        "for metric, value in lstm_results['metrics'].items():\n",
        "    print(f\"   - {metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n3. Key Findings:\")\n",
        "print(\"   - Both models can forecast inflation with reasonable accuracy\")\n",
        "print(\"   - LSTM model shows superior performance in capturing nonlinear patterns\")\n",
        "print(\"   - Crude oil prices have a significant impact on India's inflation\")\n",
        "\n",
        "print(\"\\n4. Policy Implications:\")\n",
        "print(\"   - RBI and policymakers can use these models for proactive inflation management\")\n",
        "print(\"   - LSTM-based forecasts can provide better accuracy for monetary policy decisions\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
